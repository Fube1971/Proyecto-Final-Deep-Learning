# -*- coding: utf-8 -*-
"""FinalProyectDeep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z9XJbTNDWrdJSXUHGZH6RbjxuxiRh9vf

# **LOW COST GPT MODEL**

# **PROJECT 3**

**UNIVERSIDAD MILITAR NUEVA GRANADA**


*   Daniela Fuentes Bello
*   Jose Luis Pineda Barrera
*   Daren Santiago Herrera Prada

Creamos un chatbot que recomienda canciones basadas en las preferencias del usuario. Esto incluye caracter√≠sticas musicales como bailabilidad, energ√≠a, ac√∫stica, presencia en vivo, y positividad (valance).

# Definici√≥n de la Tarea y Explicaci√≥n


*   El dataset incluye informaci√≥n detallada sobre canciones, como el artista, t√≠tulo, g√©nero, y m√∫ltiples caracter√≠sticas musicales (danceability, energy, liveness, speechiness, etc.).
*   **Normalizaci√≥n**: Las caracter√≠sticas num√©ricas se normalizan para garantizar que todos los valores est√©n en la misma escala, lo que mejora la eficiencia del modelo.
"""

# Instalar dependencias
!pip install transformers torch pandas scikit-learn huggingface_hub

from transformers import MarianMTModel, MarianTokenizer, GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments
import torch
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

"""# Modelo Entrenado e Inferencia
Antes de entrenar el modelo, se normalizo ciertas caracter√≠sticas num√©ricas en el dataset, como beats.per.minute, energy, danceability, liveness, acousticness, speechiness y valance

*   **Escalamiento**: Convertir los datos a una escala com√∫n (0 a 1) evita que caracter√≠sticas con valores mayores dominen el entrenamiento.


* train_test_split para dividir los datos en un 80% para entrenamiento y un 20% para validaci√≥n
"""

# Cargar dataset
df = pd.read_csv('DataSet.csv', on_bad_lines='skip')
df = df[['artist', 'title', 'top genre', 'danceability', 'loudness.dB', 'energy',
         'liveness', 'speechiness', 'beats.per.minute', 'acousticness', 'valance']]

# Normalizar caracter√≠sticas relevantes
columns_to_normalize = ['beats.per.minute', 'energy', 'danceability',
                        'liveness', 'acousticness', 'speechiness', 'valance']
df[columns_to_normalize] = df[columns_to_normalize].apply(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

# Crear textos de entrada y salida para el entrenamiento
df['input_text'] = (
    "Recomi√©ndame una canci√≥n del g√©nero " + df['top genre'] +
    " con caracter√≠sticas de bailabilidad " + df['danceability'].astype(str) +
    ", energ√≠a " + df['energy'].astype(str) +
    ", y presencia " + df['liveness'].astype(str) + "."
)
df['output_text'] = "El g√©nero recomendado es " + df['top genre'] + "."

# Dividir el dataset en entrenamiento y validaci√≥n
train_texts, val_texts = train_test_split(df[['input_text', 'output_text']], test_size=0.2, random_state=42)

# Dataset personalizado para Hugging Face
class SongRecommendationDataset(Dataset):
    def __init__(self, texts, tokenizer, max_length=512):
        self.texts = texts.reset_index(drop=True)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        input_text = str(self.texts.iloc[idx]['input_text'])
        output_text = str(self.texts.iloc[idx]['output_text'])
        encodings = self.tokenizer(
            input_text, text_pair=output_text, truncation=True, max_length=self.max_length, padding="max_length"
        )
        input_ids = encodings["input_ids"]
        attention_mask = encodings["attention_mask"]
        labels = input_ids.copy()
        return {
            "input_ids": torch.tensor(input_ids),
            "attention_mask": torch.tensor(attention_mask),
            "labels": torch.tensor(labels),
        }

"""# Selecci√≥n del Modelo

Elegimos por usar un modelo GPT-2 (distilgpt2) para generar recomendaciones de canciones, y modelos de traducci√≥n de MarianMT (opus-mt-es-en y opus-mt-en-es) para gestionar la entrada y salida en espa√±ol.



*   **DistilGPT-2**: Es una versi√≥n reducida y eficiente de GPT-2.
*   **Modelos de Traducci√≥n MarianMT**: Estos modelos aseguran que el chatbot pueda funcionar tanto en ingl√©s como en espa√±ol, lo que ampl√≠a su usabilidad.

**TrainingArguments** para definir los par√°metros de entrenamiento. Esto es crucial para ajustar c√≥mo se entrena tu modelo.

## Parametros Utilizados:



*   **learning_rate=5e-5**: Tasa de aprendizaje moderada, ajustada para un entrenamiento estable.
*   **per_device_train_batch_size=8**: Tama√±o del lote que usa la GPU durante el entrenamiento.
* **evaluation_strategy**="epoch": Eval√∫a el modelo al final de cada √©poca.
* **num_train_epochs**=3: El modelo se entrena durante 3 √©pocas, un n√∫mero adecuado para evitar el sobreajuste.
* **weight_decay**=0.01: Ayuda a prevenir el sobreajuste aplicando un decaimiento en los pesos.
"""

# Cargar modelo y tokenizer GPT
tokenizer = GPT2Tokenizer.from_pretrained("distilgpt2")
model = GPT2LMHeadModel.from_pretrained("distilgpt2")
tokenizer.pad_token = tokenizer.eos_token

# Crear datasets
train_dataset = SongRecommendationDataset(train_texts, tokenizer)
val_dataset = SongRecommendationDataset(val_texts, tokenizer)

# Configuraci√≥n de entrenamiento
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    save_total_limit=2,
    logging_dir="./logs",
)

# Entrenamiento del modelo
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
)

print("Entrenando el modelo...")
trainer.train()

"""# Inferencia y Uso del Modelo Entrenado

El chatbot convierte la entrada del usuario en ingl√©s, utiliza GPT-2 para generar recomendaciones, y luego traduce el resultado de vuelta al espa√±ol.
"""

# Modelos de traducci√≥n
es_to_en_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-es-en")
es_to_en_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-es-en")

en_to_es_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-es")
en_to_es_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-es")

# Funci√≥n para traducir del espa√±ol al ingl√©s
def translate_to_en(text):
    inputs = es_to_en_tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    translated = es_to_en_model.generate(**inputs)
    return es_to_en_tokenizer.decode(translated[0], skip_special_tokens=True)

# Funci√≥n para traducir del ingl√©s al espa√±ol
def translate_to_es(text):
    inputs = en_to_es_tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    translated = en_to_es_model.generate(**inputs)
    return en_to_es_tokenizer.decode(translated[0], skip_special_tokens=True)

# Interpretar descripciones ampliadas
def interpret_extended_description(description):
    mapping = {
        "extremadamente": 0.95,
        "muy": 0.8,
        "bastante": 0.65,
        "moderadamente": 0.5,
        "ligeramente": 0.35,
        "poco": 0.2,
        "casi nada": 0.1,
    }
    for keyword, value in mapping.items():
        if keyword in description:
            return value
    return 0.5

"""## Generaci√≥n de Recomendaci√≥n Basada en Preferencias

implementado un sistema de recomendaci√≥n basado en similitudes entre las caracter√≠sticas musicales del usuario y las canciones disponibles en el dataset
"""

# Mantener registro de canciones recomendadas
recommended_songs = set()

# Preguntar preferencias al usuario
def ask_user_with_more_features():
    print("Chatbot: Hola, ¬°vamos a encontrar la canci√≥n perfecta para ti!")

    genre = input("Chatbot: ¬øQu√© g√©nero de m√∫sica prefieres? (Ejemplo: pop, rock, jazz): ").strip().lower()
    danceability_desc = input("Chatbot: ¬øC√≥mo describir√≠as la bailabilidad que buscas? (Ej: Extremadamente, muy, bastante, moderadamente, ligeramente, poco, casi nada): ").strip().lower()
    danceability = interpret_extended_description(danceability_desc)

    energy_desc = input("Chatbot: ¬øQu√© nivel de energ√≠a prefieres? (Ej: Extremadamente, muy, bastante, moderadamente, ligeramente, poco, casi nada): ").strip().lower()
    energy = interpret_extended_description(energy_desc)

    liveness_desc = input("Chatbot: ¬øQu√© nivel de presencia en vivo prefieres? (Ej: Extremadamente, muy, bastante, moderadamente, ligeramente, poco, casi nada): ").strip().lower()
    liveness = interpret_extended_description(liveness_desc)

    acousticness_desc = input("Chatbot: ¬øQu√© nivel de ac√∫stica prefieres? (Ej: Extremadamente, muy, bastante, moderadamente, ligeramente, poco, casi nada): ").strip().lower()
    acousticness = interpret_extended_description(acousticness_desc)

    valance_desc = input("Chatbot: ¬øQu√© nivel de positividad o felicidad prefieres? (Ej: Extremadamente, muy, bastante, moderadamente, ligeramente, poco, casi nada): ").strip().lower()
    valance = interpret_extended_description(valance_desc)

    user_preferences = {
        "genre": genre,
        "danceability": danceability,
        "energy": energy,
        "liveness": liveness,
        "acousticness": acousticness,
        "valance": valance
    }

    print(f"\nChatbot: ¬°Perfecto! Estoy buscando una canci√≥n que cumpla con tus preferencias...\n")
    return user_preferences

# Generar recomendaci√≥n
def recommend_genre_with_similarities(user_preferences, df):
    genre = user_preferences["genre"]
    preferences_vector = np.array([
        user_preferences["danceability"], user_preferences["energy"],
        user_preferences["liveness"], user_preferences["acousticness"],
        user_preferences["valance"]
    ])

    if genre in df['top genre'].str.lower().values:
        recommendations = df[df['top genre'].str.lower() == genre]
        recommendations = recommendations[~recommendations['title'].isin(recommended_songs)]
        if not recommendations.empty:
            song = recommendations.sample(1).iloc[0]
            recommended_songs.add(song['title'])
            return f"Te recomiendo '{song['title']}' de {song['artist']} en el g√©nero '{song['top genre']}'."

    # Buscar por similitud
    print("No encontr√© canciones exactas. Buscando la m√°s cercana...")
    def calculate_distance(row):
        song_vector = np.array([row["danceability"], row["energy"],
                                row["liveness"], row["acousticness"],
                                row["valance"]])
        return np.linalg.norm(preferences_vector - song_vector)

    df["distance"] = df.apply(calculate_distance, axis=1)
    closest_songs = df[~df['title'].isin(recommended_songs)].nsmallest(1, "distance")

    if not closest_songs.empty:
        closest_song = closest_songs.iloc[0]
        recommended_songs.add(closest_song['title'])
        return f"No encontr√© una coincidencia exacta, pero te recomiendo '{closest_song['title']}' de {closest_song['artist']} en el g√©nero '{closest_song['top genre']}'."

    return "No encontr√© canciones que coincidan con tus preferencias."

# Ciclo de interacci√≥n
while True:
    user_preferences = ask_user_with_more_features()
    chatbot_response = recommend_genre_with_similarities(user_preferences, df)
    print("Chatbot:", chatbot_response)

    another = input("Chatbot: ¬øTe gustar√≠a otra recomendaci√≥n? (s√≠/no): ").strip().lower()
    if another not in ["s√≠", "si", "yes"]:
      print("Chatbot: ¬°Hasta luego! Espero haberte ayudado. üéµ")
    break